{
  "metadata": {
    "name": "Public_Library_History",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 📚 Analysis of Public Library Data"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n### 원천 데이터 : 문화 빅데이터 플랫폼\n\n- 공공 도서관 대출정보 (2023.01 ~ 2023.02)\n- 도서관 정보 (2023.05)\n- 공공 도서관 소장도서 (2023.05)\n\n\n### 기술 스택\n\n\u003cimg src\u003d\"https://img.shields.io/badge/Python-3776AB?style\u003dfor-the-badge\u0026logo\u003dPython\u0026logoColor\u003dwhite\"\u003e \n\u003cimg src\u003d\"https://img.shields.io/badge/Apache%20Airflow-017CEE?style\u003dfor-the-badge\u0026logo\u003dApache%20Airflow\u0026logoColor\u003dwhite\"\u003e \n\u003cimg src\u003d\"https://img.shields.io/badge/Apache%20Spark-E25A1C?style\u003dfor-the-badge\u0026logo\u003dApache%20Spark\u0026logoColor\u003dwhite\"\u003e \n\u003cimg src\u003d\"https://img.shields.io/badge/Apache%20Zeppelin-D22128?style\u003dfor-the-badge\u0026logo\u003dApache\u0026logoColor\u003dwhite\"\u003e \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 데이터 파이프라인\n\n##### ✔ spark-step-1 : 필요 column만 추출한 base table 생성\n    - loan_base : 월별 데이터를 통합한 2023년 1월~5월 대여 정보 테이블 생성\n    - lbrry_base : 도서관 정보 (도서관명, 도서관 코드, 주소 등)\n    - book_base : 도서 정보 (일렼번호, 제목명, 저자명, ISBN 등)\n    \n##### ✔ spark-step-2 : 도서관-대여-도서 테이블 병합 후 partition table 생성\n    - partition : LBRRY_CD (도서관 코드)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "print(\"%html \u003ch3\u003eData Pipeline Graph\u003c/h3\u003e\")\nprint(\"\u003cimg src\u003d\u0027https://user-images.githubusercontent.com/95599133/249003358-34bae4c3-e632-4820-bdd9-1be3a9f312ec.png\u0027 /\u003e\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nlbrry_base \u003d spark.read.parquet(\"file:///home/sub/cong/Library-Data-Analysis/data/base/lbrry_base\")\nlbrry_base.createOrReplaceTempView(\u0027tb_lbrry\u0027)\n\nlbrry \u003d spark.sql(\"\"\"SELECT LBRRY_CD, LBRRY_NM, ONE_AREA_NM, TWO_AREA_NM, LBRRY_ADDR FROM tb_lbrry\"\"\")\n\none_area \u003d spark.sql(\"SELECT DISTINCT ONE_AREA_NM FROM tb_lbrry ORDER BY ONE_AREA_NM\")\none_area_nm \u003d [value[0] for value in one_area.select(\u0027ONE_AREA_NM\u0027).collect()]\n\narea_dict\u003d[]\nfor one in one_area_nm:\n    two_area \u003d spark.sql(f\"SELECT DISTINCT TWO_AREA_NM, TWO_AREA_NM FROM tb_lbrry WHERE ONE_AREA_NM \u003d \u0027{one}\u0027 ORDER BY TWO_AREA_NM\")\n    area_dict.append(([value[0][0] for value in two_area.select(\u0027TWO_AREA_NM\u0027).collect()],one))\n\nprint(\u0027Load lbrry_info_tb\u0027)\n\ndf_partition\u003d spark.read.parquet(\"file:///home/sub/cong/Library-Data-Analysis/data/partition/\")\ndf_partition.createOrReplaceTempView(\"tb_partition\")\n\nloan \u003d spark.sql(\"\"\"SELECT CTRL_NO, TITLE_NM, ISBN_THIRTEEN_NO, LBRRY_CD, LBRRY_NM, BOOK_KEY_NO, MBER_SEQ_NO_VALUE, LON_YEAR, LON_MONTH, LON_DAY\n                        FROM tb_partition\"\"\")\n                        \n# df_loan.cached()\nloan.createOrReplaceTempView(\"tb_loan\")\n\nstats_loan \u003d spark.sql(\"\"\"SELECT LBRRY_NM, LON_MONTH, LON_DAY, count(*) as CNT\n                        FROM tb_loan\n                        WHERE LON_YEAR \u003d \u00272023\u0027\n                        GROUP BY ROLLUP(LBRRY_NM,LON_MONTH, LON_DAY)\n                        ORDER BY LBRRY_NM, LON_MONTH, LON_DAY\n                        \"\"\")\n\nfrom pyspark.sql.functions import countDistinct\n\ncount\u003dstats_loan.select(countDistinct(\"LBRRY_NM\")).collect()[0][0]\n                        \nstats_loan.cache()\nstats_loan.createOrReplaceTempView(\u0027tb_stats_loan\u0027)\n\nprint(f\u0027Load stats_loan_tb - 도서관 {count} 장소 load\u0027)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 🏢 전국 도서관 정보 조회"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nsub_area \u003d z.select(\u0027조회할 상위 지역명을 선택하세요\u0027,area_dict,\u0027서울특별시\u0027)\n\nprint(\u0027%html \u003ch5\u003e 🔎 하위 지역 검색결과:\u003c/h5\u003e\u0027)\nfor s in sub_area:\n    print(s, end \u003d\u0027 \u0027)\n    "
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nsearch_area1 \u003d z.input(\"상위 지역명을 입력하세요\",\u0027서울특별시\u0027)\nsearch_area2 \u003d z.input(\"하위 지역명을 입력하세요\",\u0027서초구\u0027)\nsearch_area_add \u003d z.input(\"동명 또는 도서관 이름을 입력하세요\",\u0027반포\u0027)\n\nresult \u003d spark.sql(f\"SELECT LBRRY_CD,LBRRY_TY_NM,LBRRY_NM,LBRRY_ADDR FROM tb_lbrry WHERE ONE_AREA_NM \u003d \u0027{search_area1}\u0027 and TWO_AREA_NM \u003d \u0027{search_area2}\u0027 and LBRRY_NM LIKE \u0027%{search_area_add}%\u0027 \")\nresult.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "${search_lbr}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 🔎 도서관 별 대여내역 통계"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\nSELECT LON_MONTH, CNT FROM tb_stats_loan WHERE LBRRY_NM \u003d\u0027${search_lbrry_nm}\u0027 and LON_DAY IS NULL;\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\nSELECT TO_DATE(CONCAT(\u00272023\u0027,LON_MONTH,LON_DAY),\u0027yyyyMMdd\u0027) as LON_DATE, CNT FROM tb_stats_loan WHERE LBRRY_NM \u003d\u0027${search_lbrry_nm}\u0027 and LON_MONTH IS NOT NULL and LON_DAY IS NOT NULL"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\nSELECT TO_DATE(CONCAT(\u00272023\u0027,LON_MONTH,LON_DAY),\u0027yyyyMMdd\u0027) as LON_DATE, CNT FROM tb_stats_loan WHERE LBRRY_NM \u003d\u0027${search_lbrry_nm}\u0027 and LON_MONTH \u003d \u0027${search_month}\u0027 and LON_DAY IS NOT NULL; "
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n"
    }
  ]
}